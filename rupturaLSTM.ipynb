{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GUIDELINE\n",
    "# 1 funcao que testa tudo.\n",
    "\n",
    "# deveria haver um alinhamento completo das estruturas de dados\n",
    "\n",
    "# mas nao adianta se eu nao souber o problema que eu quero resolver.\n",
    "\n",
    "# OBJETIVO - score de presenca. Quantos porcento de produto que tem na prateleira.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Historico\n",
    "- Rede dupla e/ou com 100 neuronios: ruim. Nos primeiros passos o resultado fica razoavel, mas quando avanca piora.\n",
    "- Rede unica com 10 neuronios: bom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://machinelearningmastery.com/timedistributed-layer-for-long-short-term-memory-networks-in-python/\n",
    "import sys \n",
    "import json\n",
    "import numpy as np # linear algebra\n",
    "import matplotlib.pyplot as plt # this is used for the plot the graph \n",
    "import math\n",
    "import collections\n",
    "import pandas as pd\n",
    "\n",
    "## for Deep-learing:\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Lambda\n",
    "from keras.models import model_from_json\n",
    "from tensorflow.python.keras.callbacks import TensorBoard\n",
    "\n",
    "from itertools import product\n",
    "from functools import partial\n",
    "from time import time\n",
    "\n",
    "from core.DataExploration import DataExploration\n",
    "from core.ModelIndicators import ModelIndicators\n",
    "from ruptura.CreateBatch import CreateBatch\n",
    "from ruptura.RupturaPrediction import RupturaPrediction\n",
    "from ruptura.RupturaNeuralNetwork import RupturaNeuralNetwork\n",
    "\n",
    "def defineLossWeights(yUnknow):\n",
    "    weigths = []\n",
    "    for y in yUnknow:\n",
    "        if y == 0:\n",
    "            weigths.append(1)\n",
    "        else:\n",
    "            weigths.append(0.1)\n",
    "    return weigths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = '0-1-0'\n",
    "referenceDate = '1/03/2019'\n",
    "modelName = 'model-' + version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CARREGAMENTO DOS DADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "createBatch = CreateBatch(version)\n",
    "X, Y, Ytest, lastX = createBatch.batch('barbieri-ymod.json') # Tem que resolver esse warning\n",
    "xUnknow, yUnknow = createBatch.getUnknwows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL DEFINITION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "weightVector = defineLossWeights(yUnknow)\n",
    "time_steps = X.shape[1]\n",
    "x_dimension = X.shape[2]\n",
    "y_dimension = Y.shape[2]\n",
    "if len(weightVector) != y_dimension:\n",
    "    raise Exception('custom loss weights is not defined correctly')\n",
    "\n",
    "rupNN = RupturaNeuralNetwork(modelName)\n",
    "newModel = False\n",
    "\n",
    "if newModel:\n",
    "    n_neurons = 12\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(n_neurons, input_shape=(time_steps, x_dimension), return_sequences=True)) \n",
    "    model.add(TimeDistributed(Dense(y_dimension, activation='softmax')))\n",
    "    #model.add(LSTM(n_neurons, input_shape=(time_steps, x_dimension), return_sequences=True)) \n",
    "    #model.add(TimeDistributed(Dense(x_dimension, activation='softmax')))\n",
    "    model.compile(\n",
    "        loss=rupNN.getCustomLoss((batch_size,time_steps), weightVector),\n",
    "        optimizer='adam')\n",
    "    print('MODEL CREATED\\n')\n",
    "    print(model.summary())\n",
    "else:\n",
    "    model = rupNN.loadModel((batch_size,time_steps), weightVector)  # Y dimensions are needed for custom loss definitions\n",
    "    print('MODEL LOADED\\n')\n",
    "    print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cut1 = batch_size\n",
    "cut2 = X.shape[0] - X.shape[0]%batch_size\n",
    "Xval, Xtrain,_ = np.split(X,[cut1,cut2])\n",
    "Yval, Ytrain,_ = np.split(Y,[cut1,cut2])\n",
    "for step in range(30):\n",
    "    n_epoch = 100\n",
    "    model.fit(Xtrain, Ytrain, \n",
    "                  epochs=n_epoch, \n",
    "                  batch_size= batch_size, \n",
    "                  validation_data=(Xval, Yval),\n",
    "                  verbose=2)\n",
    "    rupNN.saveModel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rupPred = RupturaPrediction(X)\n",
    "rupPred.DESCONHECIDO = [0,0,1]\n",
    "rupPred.addLastX(lastX)\n",
    "rupPred.validate(Ytest, model)\n",
    "dataScore = rupPred.calculateDataScore()  # passo que define a validacao\n",
    "rupPred.plotScore(dataScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xnext = []\n",
    "for xBatch, point in zip(X, lastX):\n",
    "    #print(point)\n",
    "    print(point.shape)\n",
    "    xnext.append(np.append(xBatch,[point],axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = dataScore.score.tolist()\n",
    "ytrue = dataScore.Inadimplente.tolist()\n",
    "ytrue = [int(x) for x in ytrue]\n",
    "modelIndicators = ModelIndicators(version)\n",
    "modelIndicators.TARGET_SCORE_CUT = 30\n",
    "modelIndicators.setPredProbs(ytrue,pred)\n",
    "indic = modelIndicators.allIndicators()\n",
    "file = open('ruptura-indicators.csv','a+')\n",
    "file.write('\\n' + 'version;' + version + ';' + 'referenceDate;' + referenceDate + '\\n')\n",
    "for i in range(len(indic)):\n",
    "    file.write(str(indic.index[i]) + ';' + str(indic.iloc[i,0]) + '\\n')\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ESTATISTICA DESCRITIVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allT = [x.split('-') for x in createBatch.titles]\n",
    "loja = []\n",
    "prod = []\n",
    "for t in allT:\n",
    "    loja.append(t[0])\n",
    "    prod.append(t[1])\n",
    "nPontosDeVenda = len(collections.Counter(loja).keys())\n",
    "nProdutos = len(collections.Counter(prod).keys())\n",
    "xzao = []\n",
    "for x in X:\n",
    "    for xt in x:\n",
    "        xzao.append(str(xt))\n",
    "ocorrenciaCounter = collections.Counter(xzao)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
