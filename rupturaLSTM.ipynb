{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO - analisar se o Ytest que chega aqui e o Ytest que esta no data score estao corretos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Historico\n",
    "- Rede dupla e/ou com 100 neuronios: ruim. Nos primeiros passos o resultado fica razoavel, mas quando avanca piora.\n",
    "- Rede unica com 10 neuronios: bom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#https://machinelearningmastery.com/timedistributed-layer-for-long-short-term-memory-networks-in-python/\n",
    "import sys \n",
    "import json\n",
    "import numpy as np # linear algebra\n",
    "import matplotlib.pyplot as plt # this is used for the plot the graph \n",
    "import math\n",
    "import collections\n",
    "import pandas as pd\n",
    "\n",
    "## for Deep-learing:\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Lambda\n",
    "from keras.models import model_from_json\n",
    "from tensorflow.python.keras.callbacks import TensorBoard\n",
    "\n",
    "from itertools import product\n",
    "from functools import partial\n",
    "from time import time\n",
    "\n",
    "from core.DataExploration import DataExploration\n",
    "from core.ModelIndicators import ModelIndicators\n",
    "from ruptura.CreateBatch import CreateBatch\n",
    "from ruptura.RupturaPrediction import RupturaPrediction\n",
    "from ruptura.RupturaNeuralNetwork import RupturaNeuralNetwork\n",
    "from ruptura.CalculateScore import CalculateScore\n",
    "\n",
    "def defineLossWeights(yUnknow):\n",
    "    weigths = []\n",
    "    for y in yUnknow:\n",
    "        if y == 0:\n",
    "            weigths.append(1)\n",
    "        else:\n",
    "            weigths.append(0.1)\n",
    "    return weigths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = '0-1-0'\n",
    "referenceDate = '1/03/2019'\n",
    "modelName = 'model-' + version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CARREGAMENTO DOS DADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "createBatch = CreateBatch(version)\n",
    "X, Y, Ytest, lastX = createBatch.batch('barbieri-ymod.json') # Tem que resolver esse warning\n",
    "xUnknow, yUnknow = createBatch.getUnknwows()\n",
    "titles = createBatch.titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL DEFINITION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL LOADED\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 60, 12)            768       \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 60, 2)             26        \n",
      "=================================================================\n",
      "Total params: 794\n",
      "Trainable params: 794\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "weightVector = defineLossWeights(yUnknow)\n",
    "time_steps = X.shape[1]\n",
    "x_dimension = X.shape[2]\n",
    "y_dimension = Y.shape[2]\n",
    "if len(weightVector) != y_dimension:\n",
    "    raise Exception('custom loss weights is not defined correctly')\n",
    "\n",
    "rupNN = RupturaNeuralNetwork(modelName)\n",
    "newModel = False\n",
    "\n",
    "if newModel:\n",
    "    n_neurons = 12\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(n_neurons, input_shape=(time_steps, x_dimension), return_sequences=True)) \n",
    "    model.add(TimeDistributed(Dense(y_dimension, activation='softmax')))\n",
    "    #model.add(LSTM(n_neurons, input_shape=(time_steps, x_dimension), return_sequences=True)) \n",
    "    #model.add(TimeDistributed(Dense(x_dimension, activation='softmax')))\n",
    "    model.compile(\n",
    "        loss=rupNN.getCustomLoss((batch_size,time_steps), weightVector),\n",
    "        optimizer='adam')\n",
    "    print('MODEL CREATED\\n')\n",
    "    print(model.summary())\n",
    "else:\n",
    "    model = rupNN.loadModel((batch_size,time_steps), weightVector)  # Y dimensions are needed for custom loss definitions\n",
    "    print('MODEL LOADED\\n')\n",
    "    print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cut1 = batch_size\n",
    "cut2 = X.shape[0] - X.shape[0]%batch_size\n",
    "Xval, Xtrain,_ = np.split(X,[cut1,cut2])\n",
    "Yval, Ytrain,_ = np.split(Y,[cut1,cut2])\n",
    "for step in range(30):\n",
    "    n_epoch = 100\n",
    "    model.fit(Xtrain, \n",
    "              Ytrain, \n",
    "              epochs=n_epoch, \n",
    "              batch_size= batch_size, \n",
    "              validation_data=(Xval, Yval),\n",
    "              verbose=2)\n",
    "    rupNN.saveModel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VALIDATION - ANTIGA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "essa funcao depende muito do formato do Y\n"
     ]
    }
   ],
   "source": [
    "#rupPred = RupturaPrediction(X)\n",
    "#rupPred.DESCONHECIDO = xUnknow\n",
    "#rupPred.addLastX(lastX)\n",
    "#rupPred.validate(Ytest, model)\n",
    "#dataScore = rupPred.calculateDataScore()  # passo que define a validacao\n",
    "#rupPred.plotScore(dataScore)  # calculate score precisa ser um objeto separado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xnext = []\n",
    "#for xBatch, point in zip(X, lastX):\n",
    "#    #print(point)\n",
    "#    print(point.shape)\n",
    "#    xnext.append(np.append(xBatch,[point],axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred = dataScore.score.tolist()\n",
    "#ytrue = dataScore.Inadimplente.tolist()\n",
    "#ytrue = [int(x) for x in ytrue]\n",
    "#modelIndicators = ModelIndicators(version)\n",
    "#modelIndicators.TARGET_SCORE_CUT = 30\n",
    "#modelIndicators.setPredProbs(ytrue,pred)\n",
    "#indic = modelIndicators.allIndicators()\n",
    "#file = open('ruptura-indicators.csv','a+')\n",
    "#file.write('\\n' + 'version;' + version + ';' + 'referenceDate;' + referenceDate + '\\n')\n",
    "#for i in range(len(indic)):\n",
    "#    file.write(str(indic.index[i]) + ';' + str(indic.iloc[i,0]) + '\\n')\n",
    "#file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOVA VALIDACAO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rupPred = RupturaPrediction(X, xUnknow)\n",
    "dayBatch = rupPred.returnSelectedDayBatch(X, -1)\n",
    "annPredictions = rupPred.walkNSteps(model, 7)\n",
    "calculateScore = CalculateScore('0-1-0')\n",
    "score = calculateScore.calculate(annPredictions)\n",
    "scoreY = calculateScore.calculate(Ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OBTEM A PRIMEIRA VISITA DE CADA LOJA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores = {}\n",
    "for i_batch, clientProd in enumerate(titles):\n",
    "    store, _ = clientProd.split('-')\n",
    "    if store in stores:\n",
    "        stores[store]['iBatch'].append(i_batch)\n",
    "    else:\n",
    "        stores[store] = {}\n",
    "        stores[store]['iBatch'] = [i_batch]\n",
    "for store in stores:\n",
    "    for day in range(Ytest.shape[1]):\n",
    "        visitFound = False\n",
    "        for i_batch in stores[store]['iBatch']:\n",
    "            if Ytest[i_batch][day][1] != 1:\n",
    "                stores[store]['visitDay'] = day\n",
    "                visitFound = True\n",
    "                break\n",
    "        if visitFound:\n",
    "            break\n",
    "    if not visitFound:\n",
    "        stores[store]['visitDay'] = -1    \n",
    "\n",
    "#allVist = []  - contagem das visitas\n",
    "#for store in stores:\n",
    "#    allVist.append(stores[store]['visitDay'])\n",
    "#collections.Counter(allVist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMPARACAO ENTRE A VISITA E O QUE A REDE NEURAL PREVIU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoreC = []\n",
    "scoreCY = []\n",
    "for store in stores:\n",
    "    visitDay = stores[store]['visitDay']\n",
    "    if visitDay == -1:\n",
    "        continue\n",
    "    else:\n",
    "        #print(stores[store]['visitDay'])\n",
    "        #print(stores[store]['iBatch'])\n",
    "        for i_batch in stores[store]['iBatch']:\n",
    "            scoreC.append(score[i_batch][visitDay])\n",
    "            scoreCY.append(scoreY[i_batch][visitDay])\n",
    "df = pd.DataFrame(scoreC)\n",
    "df['scoreY'] = scoreCY            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "##############################################################################################\n",
    "# SCORE\n",
    "##############################################################################################\n",
    "\n",
    "    def plotScore(self, dataScore):\n",
    "        dataScore.loc[:,'Inadimplente'] = [str(x) for x in dataScore.loc[:,'Inadimplente'].values]\n",
    "        de = DataExploration(dataScore)\n",
    "        de.setNpoints(self.PLOT_POINTS)\n",
    "        de.graphicInadimplenciaXContinuum(dataScore, 'score')\n",
    "\n",
    "    def plotAllBatches(self):\n",
    "        for i_batch in range(self.__score.shape[1]):\n",
    "            self.plotSampleOfBatch(i_batch)\n",
    "    \n",
    "    def plotSampleOfBatch(self, i_batch): #need to validate first\n",
    "        if self.__walkCounter == 0:\n",
    "            raise Exception('Cant plot sample, need to validate first')\n",
    "        pred = self.__score[:,i_batch]\n",
    "        real = self.__realValues[:,i_batch]\n",
    "        x = range(len(pred))\n",
    "        fig = plt.figure()\n",
    "        name = 'amostra-' + str(i_batch) + '-previsto-vs-real'\n",
    "        plt.title(name)\n",
    "        plt.ylim((-0.1, 1.1))  \n",
    "        plt.plot(x, pred, 'r', label='PREVISTO, x') # x\n",
    "        plt.plot(x, real, 'b', label='REAL, y') # y\n",
    "        plt.legend(loc='best')\n",
    "        fig.savefig(name + '.png',dpi=150)\n",
    "        plt.close(fig)\n",
    "     \n",
    "    \n",
    "    \n",
    "##############################################################################################\n",
    "# VALIDATION\n",
    "##############################################################################################\n",
    " \n",
    "    def validate(self,Ytest, model):\n",
    "        for i in range(self.VALIDATION_DAYS):\n",
    "            self.step(model)\n",
    "            self.__realValues.append(self.calculateScoreOfBatch(Ytest,i))\n",
    "        self.__realValues = np.array(self.__realValues)\n",
    "        self.__score = np.array(self.__score)\n",
    "    \n",
    "    def calculateDataScore(self):\n",
    "        print('essa funcao depende muito do formato do Y')\n",
    "        dataScore = []\n",
    "        for i_batch in range(self.__realValues.shape[1]):\n",
    "            predictions = []\n",
    "            for day in range(self.__realValues.shape[0]):\n",
    "                predictions.append(self.__score[day][i_batch])\n",
    "                if self.__realValues[day][i_batch] != -1:\n",
    "                    rupScore = int(100*np.max(predictions))\n",
    "                    dataScore.append((rupScore,self.__realValues[day][i_batch]))\n",
    "                    break\n",
    "        dataScore = pd.DataFrame(data=dataScore,columns=['score','Inadimplente'])\n",
    "        return dataScore\n",
    "    \n",
    "    def calculateScoreOfBatch(self, pointsBatch, time_step = -1):\n",
    "        points = self.getStepPoints(pointsBatch, time_step)\n",
    "        score = []\n",
    "        for point in points:\n",
    "            if point[1] == 1:\n",
    "                score.append(-1)\n",
    "            else:\n",
    "                score.append(point[0])\n",
    "        return score\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ESTATISTICA DESCRITIVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allT = [x.split('-') for x in createBatch.titles]\n",
    "loja = []\n",
    "prod = []\n",
    "for t in allT:\n",
    "    loja.append(t[0])\n",
    "    prod.append(t[1])\n",
    "nPontosDeVenda = len(collections.Counter(loja).keys())\n",
    "nProdutos = len(collections.Counter(prod).keys())\n",
    "xzao = []\n",
    "for x in X:\n",
    "    for xt in x:\n",
    "        xzao.append(str(xt))\n",
    "ocorrenciaCounter = collections.Counter(xzao)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
