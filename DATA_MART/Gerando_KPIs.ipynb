{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytz\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import collections\n",
    "import re\n",
    "from pymongo import MongoClient\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeSpecialCharacters(value):\n",
    "    return re.sub('[^A-Za-z0-9]+', ' ', str(value))\n",
    "\n",
    "def cleanDataColumns(data):\n",
    "    trueCol = []\n",
    "    for col in data.columns:\n",
    "        trueCol.append(removeSpecialCharacters(col))\n",
    "    data.columns = trueCol\n",
    "    return data\n",
    "\n",
    "def limpa_cpf(cpfString):\n",
    "    cpfString = cpfString.replace('.','')\n",
    "    cpfString = cpfString.replace('-','')\n",
    "    return int(cpfString)    \n",
    "\n",
    "def limpeza_de_cpfs(dados, coluna):\n",
    "    dados[coluna] = dados.loc[:,coluna].apply(limpa_cpf)\n",
    "    return dados\n",
    "            \n",
    "        \n",
    "def coluna_para_datetime(data, coluna):\n",
    "    data[coluna] = pd.to_datetime(data[coluna], format='%d/%m/%Y')\n",
    "    data[coluna] = data.loc[:,coluna].apply(date_to_Brazil_East_Utc)\n",
    "    return data\n",
    "\n",
    "def string_to_datetime(datetime_string):\n",
    "    datetime_string = datetime_string.split('/')\n",
    "    datetime_value = datetime.datetime(\n",
    "        int(datetime_string[2]),\n",
    "        int(datetime_string[1]),\n",
    "        int(datetime_string[0]))\n",
    "    return date_to_Brazil_East_Utc(datetime_value)\n",
    "\n",
    "def date_to_Brazil_East_Utc(datetime_value): # ele adianta o relogio em 3 horas\n",
    "    if str(datetime_value) == 'NaT':\n",
    "        datetime_value = datetime.datetime(1500,1,1) # minha data nulla e 01/01/1500\n",
    "    local = pytz.timezone(\"Brazil/East\")\n",
    "    local_dt = local.localize(datetime_value, is_dst=True) # esse is_dst e pra ambiguidades, deve ser horario de verao aqui\n",
    "    utc_dt = local_dt.astimezone(pytz.utc)\n",
    "    return utc_dt.strftime (\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "def float_latin_nan_e_zero(entry):\n",
    "    if _isNan(entry):\n",
    "        return 0.0e0\n",
    "    else:\n",
    "        return floatLatin(entry)\n",
    "    \n",
    "def floatComVirgula(entry):\n",
    "    if _isNan(entry):\n",
    "        return np.nan\n",
    "    else:\n",
    "        entry = str(entry).replace(',','')\n",
    "        return float(entry)\n",
    "        \n",
    "def floatLatin(entry):\n",
    "    if _isNan(entry):\n",
    "        return np.nan\n",
    "    entry = str(entry).replace('.','')\n",
    "    entry = str(entry).replace(',','.')\n",
    "    return float(entry)\n",
    "\n",
    "def _isNan(value):\n",
    "    if isinstance(value, str):\n",
    "        return value == 'nan'\n",
    "    else:\n",
    "        return np.isnan(value)\n",
    "\n",
    "\n",
    "# TRANSFORMACOES ESPECIFICAS DA TABELA ACORDOS\n",
    "\n",
    "def transforma_Assessoria(valor):\n",
    "    if str(valor) == 'nan':\n",
    "        return 'SEMEAR'\n",
    "    else:\n",
    "        return str(valor)\n",
    "\n",
    "def transforma_Cobrador(valor):\n",
    "    if 'Semear_Renego' in valor:\n",
    "        return 'Renegociacao'\n",
    "    elif 'Multiparcelas' in valor:\n",
    "        return 'Multiparcelas'\n",
    "    else:\n",
    "        return 'NULO'\n",
    "\n",
    "# TRANSFORMACOES ESPECIFICAS DA TABELA ACIONAMENTOS\n",
    "\n",
    "def coluna_para_datetime_hora(data, coluna):\n",
    "    data[coluna] = pd.to_datetime(data[coluna], format='%d/%m/%Y %H:%M')\n",
    "    data[coluna] = data.loc[:,coluna].apply(date_to_Brazil_East_Utc)\n",
    "    return data\n",
    "\n",
    "# TRANSFORMACOES ESPECIFICAS DO RELATORIO 3040\n",
    "\n",
    "def coluna_para_datetime_hora_seg(data, coluna):\n",
    "    data[coluna] = pd.to_datetime(data[coluna], format='%Y-%m-%d %H:%M:%S')\n",
    "    data[coluna] = data.loc[:,coluna].apply(date_to_Brazil_East_Utc)\n",
    "    return data\n",
    "\n",
    "def string_para_datetime(datetime_string):\n",
    "    return datetime.datetime.strptime(datetime_string, '%Y-%m-%d %H:%M:%S')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_01 = pd.read_csv('3040_01_2019.csv', sep=';', encoding='latin-1', dtype=str)\n",
    "dados_02 = pd.read_csv('3040_02_2019.csv', sep=';', encoding='latin-1', dtype=str)\n",
    "dados_03 = pd.read_csv('3040_03_2019.csv', sep=';', encoding='latin-1', dtype=str)\n",
    "dados_04 = pd.read_csv('3040_04_2019.csv', sep=';', encoding='latin-1', dtype=str)\n",
    "dados_05 = pd.read_csv('3040_05_2019.csv', sep=';', encoding='latin-1', dtype=str)\n",
    "dados_06 = pd.read_csv('3040_06_2019.csv', sep=';', encoding='latin-1', dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "acionamentos = pd.read_csv('Acionamentos_01012019_a_30062019.csv', sep=';', encoding='latin-1', dtype=str)\n",
    "acionamentos = cleanDataColumns(acionamentos)\n",
    "cpf_null = acionamentos[acionamentos.loc[:,'CPF CNPJ'].isnull()].index\n",
    "acionamentos = acionamentos.drop(cpf_null)\n",
    "acionamentos = acionamentos.reset_index(drop=True)\n",
    "datahora = []\n",
    "for i in acionamentos.index:\n",
    "    datahora.append(acionamentos.loc[i,'Data'] + ' ' + acionamentos.loc[i,'Hor rio'])\n",
    "    \n",
    "acionamentos['datahora'] = datahora\n",
    "acionamentos = coluna_para_datetime_hora(acionamentos, 'datahora')\n",
    "acionamentos['datahora'] = [string_para_datetime(x) for x in acionamentos.loc[:,'datahora'].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_01 = cleanDataColumns(dados_01)\n",
    "dados_02 = cleanDataColumns(dados_02)\n",
    "dados_03 = cleanDataColumns(dados_03)\n",
    "dados_04 = cleanDataColumns(dados_04)\n",
    "dados_05 = cleanDataColumns(dados_05)\n",
    "dados_06 = cleanDataColumns(dados_06)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_inicio = datetime.datetime.strptime('2019-02-01 00:00:00', '%Y-%m-%d %H:%M:%S')\n",
    "data_fim = datetime.datetime.strptime('2019-02-28 23:59:59', '%Y-%m-%d %H:%M:%S')\n",
    "intervalo_de_acionamentos = acionamentos[\n",
    "        (acionamentos.loc[:,'datahora'] < data_fim) &\n",
    "        (acionamentos.loc[:,'datahora'] > data_inicio)].copy()\n",
    "print('Numero de acionamentos neste intervalo:  ', len(set(intervalo_de_acionamentos.loc[:,'CPF CNPJ'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_inicio = datetime.datetime.strptime('2019-03-01 00:00:00', '%Y-%m-%d %H:%M:%S')\n",
    "data_fim = datetime.datetime.strptime('2019-03-31 23:59:59', '%Y-%m-%d %H:%M:%S')\n",
    "intervalo_de_acionamentos = acionamentos[\n",
    "        (acionamentos.loc[:,'datahora'] < data_fim) &\n",
    "        (acionamentos.loc[:,'datahora'] > data_inicio)].copy()\n",
    "print('Numero de acionamentos neste intervalo:  ', len(set(intervalo_de_acionamentos.loc[:,'CPF CNPJ'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_inicio = datetime.datetime.strptime('2019-04-01 00:00:00', '%Y-%m-%d %H:%M:%S')\n",
    "data_fim = datetime.datetime.strptime('2019-04-30 23:59:59', '%Y-%m-%d %H:%M:%S')\n",
    "intervalo_de_acionamentos = acionamentos[\n",
    "        (acionamentos.loc[:,'datahora'] < data_fim) &\n",
    "        (acionamentos.loc[:,'datahora'] > data_inicio)].copy()\n",
    "print('Numero de acionamentos neste intervalo:  ', len(set(intervalo_de_acionamentos.loc[:,'CPF CNPJ'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_inicio = datetime.datetime.strptime('2019-05-01 00:00:00', '%Y-%m-%d %H:%M:%S')\n",
    "data_fim = datetime.datetime.strptime('2019-05-31 23:59:59', '%Y-%m-%d %H:%M:%S')\n",
    "intervalo_de_acionamentos = acionamentos[\n",
    "        (acionamentos.loc[:,'datahora'] < data_fim) &\n",
    "        (acionamentos.loc[:,'datahora'] > data_inicio)].copy()\n",
    "print('Numero de acionamentos neste intervalo:  ', len(set(intervalo_de_acionamentos.loc[:,'CPF CNPJ'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_inicio = datetime.datetime.strptime('2019-06-01 00:00:00', '%Y-%m-%d %H:%M:%S')\n",
    "data_fim = datetime.datetime.strptime('2019-06-30 23:59:59', '%Y-%m-%d %H:%M:%S')\n",
    "intervalo_de_acionamentos = acionamentos[\n",
    "        (acionamentos.loc[:,'datahora'] < data_fim) &\n",
    "        (acionamentos.loc[:,'datahora'] > data_inicio)].copy()\n",
    "print('Numero de acionamentos neste intervalo:  ', len(set(intervalo_de_acionamentos.loc[:,'CPF CNPJ'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_inicio = datetime.datetime.strptime('2019-07-01 00:00:00', '%Y-%m-%d %H:%M:%S')\n",
    "data_fim = datetime.datetime.strptime('2019-07-30 23:59:59', '%Y-%m-%d %H:%M:%S')\n",
    "intervalo_de_acionamentos = acionamentos[\n",
    "        (acionamentos.loc[:,'datahora'] < data_fim) &\n",
    "        (acionamentos.loc[:,'datahora'] > data_inicio)].copy()\n",
    "print('Numero de acionamentos neste intervalo:  ', len(set(intervalo_de_acionamentos.loc[:,'CPF CNPJ'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corte_pdd(dados):\n",
    "    dados.VlrPDD = dados.VlrPDD.apply(floatComVirgula)\n",
    "    dados_corte = dados[dados.VlrPDD > 1e-5].copy() # Remove aquels VlrPDD 0\n",
    "    dados_corte.DiasAtraso = dados_corte.DiasAtraso.astype(int)\n",
    "    numero_5 = len(set(dados_corte[dados_corte.DiasAtraso >= 5].CpfCgc))\n",
    "    numero_30 = len(set(dados_corte[dados_corte.DiasAtraso >= 30].CpfCgc))\n",
    "    numero_60 = len(set(dados_corte[dados_corte.DiasAtraso >= 60].CpfCgc))\n",
    "    print('5 dias: ', numero_5,\n",
    "         '  30 dias: ', numero_30,\n",
    "         '  60 dias: ', numero_60)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 dias:  62555   30 dias:  30294   60 dias:  19414\n"
     ]
    }
   ],
   "source": [
    "corte_pdd(dados_06) # CORTES OBTIDOS AQUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_05.VlrPDD = dados_05.VlrPDD.apply(floatComVirgula)\n",
    "dados_corte = dados_05[dados_05.VlrPDD > 1e-5].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_corte.DiasAtraso = dados_corte.DiasAtraso.astype(int)\n",
    "dados_corte[dados_corte.DiasAtraso >= 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(dados_corte[dados_corte.DiasAtraso >= 5].CpfCgc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(dados_corte[dados_corte.DiasAtraso >= 30].CpfCgc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(dados_corte[dados_corte.DiasAtraso >= 60].CpfCgc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "labels = ['Fev', 'Mar', 'Abr', 'Mai', 'Jun']\n",
    "acionam = [23, 6129, 13687, 17129, 25020]\n",
    "atraso_5 = [63061, 66732, 67356, 60978, 62555]\n",
    "atraso_30 = [30909, 33727, 34968, 31584, 30294]\n",
    "atraso_60 = [18932, 20258, 23307, 19646, 19414]\n",
    "\n",
    "x = np.arange(len(labels))  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "r1 = x\n",
    "r2 = [x + width for x in r1]\n",
    "r3 = [x + width for x in r2]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(r1, acionam, width, label='Acionamentos')\n",
    "rects2 = ax.bar(r2, atraso_60, width, label='Atraso 60')\n",
    "rects3 = ax.bar(r3, atraso_30, width, label='Atraso 30')\n",
    "#rects4 = ax.bar(xPlot + width/2, atraso_5, width, label='Atraso 5')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Número')\n",
    "ax.set_title('CPFs acionados por CPFs em atraso')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "\n",
    "\n",
    "def autolabel(rects):\n",
    "    \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate('{}'.format(height),\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "\n",
    "#autolabel(rects1)\n",
    "#autolabel(rects2)\n",
    "#autolabel(rects3)\n",
    "#autolabel(rects4)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "figura = plt.figure()\n",
    "\n",
    "# set width of bar\n",
    "barWidth = 0.2\n",
    " \n",
    "# set height of bar\n",
    "labels = ['Fev', 'Mar', 'Abr', 'Mai', 'Jun']\n",
    "acionam = [23, 6129, 13687, 17129, 25020]\n",
    "atraso_5 = [63061, 66732, 67356, 60978, 62555]\n",
    "atraso_30 = [30909, 33727, 34968, 31584, 30294]\n",
    "atraso_60 = [18932, 20258, 23307, 19646, 19414]\n",
    "\n",
    "bars1 = acionam\n",
    "bars2 = atraso_60\n",
    "bars3 = atraso_30\n",
    "bars4 = atraso_5\n",
    " \n",
    "# Set position of bar on X axis\n",
    "r1 = np.arange(len(bars1))\n",
    "r2 = [x + barWidth for x in r1]\n",
    "r3 = [x + barWidth for x in r2]\n",
    "r4 = [x + barWidth for x in r3]\n",
    " \n",
    "# Make the plot\n",
    "plt.bar(r1, bars1, color='k', width=barWidth, edgecolor='white', label='Acionamentos')\n",
    "plt.bar(r2, bars2, color='b', width=barWidth, edgecolor='white', label='Atraso 60 dias')\n",
    "plt.bar(r3, bars3, color='g', width=barWidth, edgecolor='white', label='Atraso 30 dias')\n",
    "plt.bar(r4, bars4, color='r', width=barWidth, edgecolor='white', label='Atraso 5 dias')\n",
    " \n",
    "# Add xticks on the middle of the group bars\n",
    "plt.xlabel('ACIONAMENTOS VS CPFs ATRASADOS')\n",
    "plt.ylabel('Numero de CPFs')\n",
    "plt.xticks([r + barWidth for r in range(len(bars1))], labels)\n",
    " \n",
    "# Create legend & Show graphic\n",
    "plt.legend()\n",
    "figura.savefig('sada',dpi=150)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RELATORIO DE ROLAGEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_01.DiasAtraso = dados_01.DiasAtraso.astype(int)\n",
    "dados_02.DiasAtraso = dados_02.DiasAtraso.astype(int)\n",
    "dados_03.DiasAtraso = dados_03.DiasAtraso.astype(int)\n",
    "dados_04.DiasAtraso = dados_04.DiasAtraso.astype(int)\n",
    "dados_05.DiasAtraso = dados_05.DiasAtraso.astype(int)\n",
    "dados_06.DiasAtraso = dados_06.DiasAtraso.astype(int)\n",
    "dados_01.CodProduto = dados_01.CodProduto.astype(int)\n",
    "dados_02.CodProduto = dados_02.CodProduto.astype(int)\n",
    "dados_03.CodProduto = dados_03.CodProduto.astype(int)\n",
    "dados_04.CodProduto = dados_04.CodProduto.astype(int)\n",
    "dados_05.CodProduto = dados_05.CodProduto.astype(int)\n",
    "dados_06.CodProduto = dados_06.CodProduto.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CODIGOS_EP = [3064, 3065, 3069, 3070, 3071, 3072, 3077, 3078, 3081, 3086, 3087, 3088, 3092, 3095, 3096, 3103, 3105]\n",
    "\n",
    "def Numeros_de_rolagem(dados):    \n",
    "    rol_1_30 = len(dados[(dados.DiasAtraso >= 1) & (dados.DiasAtraso <= 30)])\n",
    "    rol_31_60 = len(dados[(dados.DiasAtraso >= 31) & (dados.DiasAtraso <= 60)])\n",
    "    rol_61_90 = len(dados[(dados.DiasAtraso >= 61) & (dados.DiasAtraso <= 90)])\n",
    "    rol_91_120 = len(dados[(dados.DiasAtraso >= 91) & (dados.DiasAtraso <= 120)])\n",
    "    rol_121_150 = len(dados[(dados.DiasAtraso >= 121) & (dados.DiasAtraso <= 150)])\n",
    "    rol_151_180 = len(dados[(dados.DiasAtraso >= 151) & (dados.DiasAtraso <= 180)])\n",
    "    return [rol_1_30, rol_31_60, rol_61_90, rol_91_120, rol_121_150, rol_151_180]\n",
    "\n",
    "def Numeros_de_rolagem_EP(dados):    \n",
    "    dados_EP = dados[dados.CodProduto.isin(CODIGOS_EP)].copy()\n",
    "    rol_1 = len(dados_EP[(dados_EP.DiasAtraso >= 0) & (dados_EP.DiasAtraso <= 5)])\n",
    "    rol_2 = len(dados_EP[(dados_EP.DiasAtraso >= 6) & (dados_EP.DiasAtraso <= 30)])\n",
    "    rol_3 = len(dados_EP[(dados_EP.DiasAtraso >= 31) & (dados_EP.DiasAtraso <= 60)])\n",
    "    rol_4 = len(dados_EP[(dados_EP.DiasAtraso >= 61) & (dados_EP.DiasAtraso <= 90)])\n",
    "    rol_5 = len(dados_EP[(dados_EP.DiasAtraso >= 91) & (dados_EP.DiasAtraso <= 120)])\n",
    "    rol_6 = len(dados_EP[(dados_EP.DiasAtraso >= 121) & (dados_EP.DiasAtraso <= 150)])\n",
    "    rol_7 = len(dados_EP[(dados_EP.DiasAtraso >= 151) & (dados_EP.DiasAtraso <= 180)])\n",
    "    rol_8 = len(dados_EP[dados_EP.DiasAtraso >= 181])\n",
    "    return [rol_1, rol_2, rol_3, rol_4, rol_5, rol_6, rol_7, rol_8]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolagens = []\n",
    "rolagens.append(Numeros_de_rolagem(dados_01))\n",
    "rolagens.append(Numeros_de_rolagem(dados_02))\n",
    "rolagens.append(Numeros_de_rolagem(dados_03))\n",
    "rolagens.append(Numeros_de_rolagem(dados_04))\n",
    "rolagens.append(Numeros_de_rolagem(dados_05))\n",
    "rolagens.append(Numeros_de_rolagem(dados_06))\n",
    "pd.DataFrame(data=rolagens).to_csv('relatorio_de_rolagens.csv',sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolagens = []\n",
    "rolagens.append(Numeros_de_rolagem_EP(dados_01))\n",
    "rolagens.append(Numeros_de_rolagem_EP(dados_02))\n",
    "rolagens.append(Numeros_de_rolagem_EP(dados_03))\n",
    "rolagens.append(Numeros_de_rolagem_EP(dados_04))\n",
    "rolagens.append(Numeros_de_rolagem_EP(dados_05))\n",
    "rolagens.append(Numeros_de_rolagem_EP(dados_06))\n",
    "pd.DataFrame(data=rolagens).to_csv('relatorio_de_rolagens_EP.csv',sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RELATORIO DE ROLAGEM FINANCEIRO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definicao do valor em aberto:\n",
    "# VlrProxParcela * (1 + diasEmAtraso / 30)\n",
    "# Se, por exemplo, o valor da parcela for 200 reais, temos:\n",
    "# Se, DiasEmAtraso = 10, entao, valor em aberto = 200.\n",
    "# Se, DiasEmAtraso = 40, entao, valor em aberto = 400.\n",
    "# tem que olhar a quantidade de parcelas abertas tambem\n",
    "\n",
    "CODIGOS_EP = [3064, 3065, 3069, 3070, 3071, 3072, 3077, 3078, 3081, 3086, 3087, 3088, 3092, 3095, 3096, 3103, 3105]\n",
    "\n",
    "def calcule_perda_financeira(dados, meses_em_atraso_base):\n",
    "    perda = []\n",
    "    cheio = str(meses_em_atraso_base) == 'CHEIO'\n",
    "    for i in dados.index:\n",
    "        meses_em_atraso_I = dados.QtdParAberta[i]\n",
    "        if cheio: \n",
    "            pass\n",
    "        elif meses_em_atraso_I >= meses_em_atraso_base and not cheio:\n",
    "            meses_em_atraso_I = meses_em_atraso_base\n",
    "        perda_financeira = meses_em_atraso_I * dados.VlrProxParcela[i]\n",
    "        perda.append(perda_financeira)\n",
    "    return sum(perda)\n",
    "    \n",
    "def Numeros_de_rolagem_EP_financeiro(dados):    \n",
    "    #rol_1 = dados[(dados.DiasAtraso >= 0) & (dados.DiasAtraso <= 5)]\n",
    "    #rol_1 = 0\n",
    "    rol_2 = dados[(dados.DiasAtraso >= 6) & (dados.DiasAtraso <= 30)]\n",
    "    rol_2 = calcule_perda_financeira(rol_2, 1)\n",
    "    rol_3 = dados[(dados.DiasAtraso >= 31) & (dados.DiasAtraso <= 60)]\n",
    "    rol_3 = calcule_perda_financeira(rol_3, 2)\n",
    "    rol_4 = dados[(dados.DiasAtraso >= 61) & (dados.DiasAtraso <= 90)]\n",
    "    rol_4 = calcule_perda_financeira(rol_4, 3)\n",
    "    rol_5 = dados[(dados.DiasAtraso >= 91) & (dados.DiasAtraso <= 120)]\n",
    "    rol_5 = calcule_perda_financeira(rol_5, 4)\n",
    "    rol_6 = dados[(dados.DiasAtraso >= 121) & (dados.DiasAtraso <= 150)]\n",
    "    rol_6 = calcule_perda_financeira(rol_6, 5)\n",
    "    rol_7 = dados[(dados.DiasAtraso >= 151) & (dados.DiasAtraso <= 180)]\n",
    "    rol_7 = calcule_perda_financeira(rol_7, 6)\n",
    "    rol_8 = dados[dados.DiasAtraso >= 181]\n",
    "    rol_8 = calcule_perda_financeira(rol_8, 'CHEIO')\n",
    "    return [0, rol_2, rol_3, rol_4, rol_5, rol_6, rol_7, rol_8]\n",
    "\n",
    "def rolagem_financeira(dados):\n",
    "    dados = cleanDataColumns(dados)\n",
    "    dados.CodProduto = dados.CodProduto.astype(int)\n",
    "    dados_EP = dados[dados.CodProduto.isin(CODIGOS_EP)].copy()\n",
    "    dados_EP.DiasAtraso = dados_EP.DiasAtraso.astype(int)\n",
    "    dados_EP.VlrProxParcela = dados_EP.VlrProxParcela.apply(floatComVirgula)\n",
    "    dados_EP.QtdParAberta = dados_EP.QtdParAberta.astype(int)\n",
    "    return Numeros_de_rolagem_EP_financeiro(dados_EP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolagem_todos = []\n",
    "dados = pd.read_excel('3040_01_2019.xlsx', sep=';', encoding='latin-1', dtype=str)\n",
    "rolagem_todos.append(rolagem_financeira(dados))\n",
    "dados = pd.read_excel('3040_02_2019.xlsx', sep=';', encoding='latin-1', dtype=str)\n",
    "rolagem_todos.append(rolagem_financeira(dados))\n",
    "dados = pd.read_excel('3040_03_2019.xlsx', sep=';', encoding='latin-1', dtype=str)\n",
    "rolagem_todos.append(rolagem_financeira(dados))\n",
    "dados = pd.read_excel('3040_04_2019.xlsx', sep=';', encoding='latin-1', dtype=str)\n",
    "rolagem_todos.append(rolagem_financeira(dados))\n",
    "dados = pd.read_excel('3040_05_2019.xlsx', sep=';', encoding='latin-1', dtype=str)\n",
    "rolagem_todos.append(rolagem_financeira(dados))\n",
    "dados = pd.read_excel('3040_06_2019.xlsx', sep=';', encoding='latin-1', dtype=str)\n",
    "rolagem_todos.append(rolagem_financeira(dados))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(rolagem_todos).to_csv('rolagem_financeira.csv',sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINANCEIRO COM PERDA CHEIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definicao do valor em aberto:\n",
    "# VlrProxParcela * (1 + diasEmAtraso / 30)\n",
    "# Se, por exemplo, o valor da parcela for 200 reais, temos:\n",
    "# Se, DiasEmAtraso = 10, entao, valor em aberto = 200.\n",
    "# Se, DiasEmAtraso = 40, entao, valor em aberto = 400.\n",
    "# tem que olhar a quantidade de parcelas abertas tambem\n",
    "\n",
    "CODIGOS_EP = [3064, 3065, 3069, 3070, \n",
    "              3071, 3072, 3077, 3078, \n",
    "              3081, 3086, 3087, 3088, \n",
    "              3092, 3095, 3096, 3103, 3105]\n",
    "\n",
    "def calcule_perda_financeira(dados, meses_em_atraso_base):\n",
    "    perda = []\n",
    "    cheio = str(meses_em_atraso_base) == 'CHEIO'\n",
    "    for i in dados.index:\n",
    "        meses_em_atraso_I = dados.QtdParAberta[i]\n",
    "        if cheio: \n",
    "            pass\n",
    "        elif meses_em_atraso_I >= meses_em_atraso_base and not cheio:\n",
    "            meses_em_atraso_I = meses_em_atraso_base\n",
    "        perda_financeira = meses_em_atraso_I * dados.VlrProxParcela[i]\n",
    "        perda.append(perda_financeira)\n",
    "    return sum(perda)\n",
    "    \n",
    "def Numeros_de_rolagem_EP_financeiro(dados):    \n",
    "    rol_1 = dados[(dados.DiasAtraso >= 0) & (dados.DiasAtraso <= 5)]\n",
    "    rol_1 = calcule_perda_financeira(rol_1, 'CHEIO')\n",
    "    rol_2 = dados[(dados.DiasAtraso >= 6) & (dados.DiasAtraso <= 30)]\n",
    "    rol_2 = calcule_perda_financeira(rol_2, 'CHEIO')\n",
    "    rol_3 = dados[(dados.DiasAtraso >= 31) & (dados.DiasAtraso <= 60)]\n",
    "    rol_3 = calcule_perda_financeira(rol_3, 'CHEIO')\n",
    "    rol_4 = dados[(dados.DiasAtraso >= 61) & (dados.DiasAtraso <= 90)]\n",
    "    rol_4 = calcule_perda_financeira(rol_4, 'CHEIO')\n",
    "    rol_5 = dados[(dados.DiasAtraso >= 91) & (dados.DiasAtraso <= 120)]\n",
    "    rol_5 = calcule_perda_financeira(rol_5, 'CHEIO')\n",
    "    rol_6 = dados[(dados.DiasAtraso >= 121) & (dados.DiasAtraso <= 150)]\n",
    "    rol_6 = calcule_perda_financeira(rol_6, 'CHEIO')\n",
    "    rol_7 = dados[(dados.DiasAtraso >= 151) & (dados.DiasAtraso <= 180)]\n",
    "    rol_7 = calcule_perda_financeira(rol_7, 'CHEIO')\n",
    "    rol_8 = dados[dados.DiasAtraso >= 181]\n",
    "    rol_8 = calcule_perda_financeira(rol_8, 'CHEIO')\n",
    "    return [rol_1, rol_2, rol_3, rol_4, rol_5, rol_6, rol_7, rol_8]\n",
    "\n",
    "def rolagem_financeira(dados):\n",
    "    dados = cleanDataColumns(dados)\n",
    "    dados.CodProduto = dados.CodProduto.astype(int)\n",
    "    dados_EP = dados[dados.CodProduto.isin(CODIGOS_EP)].copy()\n",
    "    dados_EP.DiasAtraso = dados_EP.DiasAtraso.astype(int)\n",
    "    dados_EP.VlrProxParcela = dados_EP.VlrProxParcela.apply(floatComVirgula)\n",
    "    dados_EP.QtdParAberta = dados_EP.QtdParAberta.astype(int)\n",
    "    return Numeros_de_rolagem_EP_financeiro(dados_EP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolagem_todos = []\n",
    "dados = pd.read_excel('3040_01_2019.xlsx', sep=';', encoding='latin-1', dtype=str)\n",
    "rolagem_todos.append(rolagem_financeira(dados))\n",
    "dados = pd.read_excel('3040_02_2019.xlsx', sep=';', encoding='latin-1', dtype=str)\n",
    "rolagem_todos.append(rolagem_financeira(dados))\n",
    "dados = pd.read_excel('3040_03_2019.xlsx', sep=';', encoding='latin-1', dtype=str)\n",
    "rolagem_todos.append(rolagem_financeira(dados))\n",
    "dados = pd.read_excel('3040_04_2019.xlsx', sep=';', encoding='latin-1', dtype=str)\n",
    "rolagem_todos.append(rolagem_financeira(dados))\n",
    "dados = pd.read_excel('3040_05_2019.xlsx', sep=';', encoding='latin-1', dtype=str)\n",
    "rolagem_todos.append(rolagem_financeira(dados))\n",
    "dados = pd.read_excel('3040_06_2019.xlsx', sep=';', encoding='latin-1', dtype=str)\n",
    "rolagem_todos.append(rolagem_financeira(dados))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(rolagem_todos).to_csv('rolagem_financeira_2.csv',sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
